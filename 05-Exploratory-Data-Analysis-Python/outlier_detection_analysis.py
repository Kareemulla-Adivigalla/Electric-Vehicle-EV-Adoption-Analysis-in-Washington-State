# -*- coding: utf-8 -*-
"""Outlier Detection Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1mOGQBzeFnMNOzaTZDPOxeqGlfDa2WnDL

## Business Objective:

- Objective: Identify the counties and cities in Washington state with the highest and lowest numbers of electric vehicles (EVs).

- Goal: Understand regional adoption trends and identify areas that may benefit from additional support or incentives to encourage higher adoption of EVs.

# Key Columns:
- County
- City
- State
- Postal Code
- Vehicle Location
"""

# Commented out IPython magic to ensure Python compatibility.
#Importing Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

#to display plots inline
# %matplotlib inline

from google.colab import drive

# Mount Google Drive
drive.mount('/content/gdrive')

# Access your dataset
data_path = '/content/gdrive/My Drive/Colab Notebooks/Electiric vehical/cleaned_data.csv'

df = pd.read_csv(data_path)
# Display the first few rows of the DataFrame
df.head()

df.info()

df.describe()

"""**Aggregate EV Data by County and City**"""

ev_count_by_region = df.groupby(['County', 'City']).size().reset_index(name='EV_Count')

print(ev_count_by_region.head())

"""**Calculate Z-Scores for Outlier Detection**"""

from scipy import stats

ev_count_by_region['Z_Score'] = stats.zscore(ev_count_by_region['EV_Count'])

print(ev_count_by_region['Z_Score'].describe())

"""**Identify and Isolate Outliers**"""

# Filter Outliers

outliers = ev_count_by_region[(ev_count_by_region['Z_Score'] > 2) | (ev_count_by_region['Z_Score'] < -2)]

print(outliers)

"""# Interpreting the Outliers:

# High Z-Scores (Above 2):
- The Z-scores indicate how many standard deviations away a region's EV count is from the mean. A Z-score greater than 2 generally suggests that the region has a higher-than-average number of EVs, making it an outlier.

- Seattle (King County) stands out the most, with a Z-score of 23.69, indicating a very high concentration of EVs compared to other regions.

- Other cities like Bellevue, Vancouver, Redmond, Renton, and Sammamish also have high Z-scores, indicating a significantly higher adoption of EVs.

# **Alternative Approach – Interquartile Range (IQR) Method**
"""

# Calculate IQR
Q1 = ev_count_by_region['EV_Count'].quantile(0.25)
Q3 = ev_count_by_region['EV_Count'].quantile(0.75)
IQR = Q3 - Q1

# Identify Outliers
outliers = ev_count_by_region[(ev_count_by_region['EV_Count'] < (Q1 - 1.5 * IQR)) | (ev_count_by_region['EV_Count'] > (Q3 + 1.5 * IQR))]

# Check for Outliers
print(outliers)

"""# Interpreting the Non-Outliers:
# Moderate Z-Scores (Around 0):

- The Z-scores close to 0 indicate that the number of EVs in these regions is near the average across all regions analyzed. These cities have a typical or expected level of EV adoption.

- Cities like Kennewick, Richland, West Richland, Chelan, and Leavenworth have Z-scores within a normal range, meaning their EV adoption rates are consistent with the overall distribution.
"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(12, 40))
sns.barplot(x='EV_Count', y='City', data=outliers.sort_values('EV_Count', ascending=False), hue='County')
plt.title('Outlier Regions by EV Count')
plt.xlabel('Number of EVs')
plt.ylabel('City')
plt.show()

"""**Identify the Outliers**"""

from scipy import stats

# Calculate Z-scores for the EV counts
ev_count_by_region['Z_Score'] = stats.zscore(ev_count_by_region['EV_Count'])

# Identify outliers with Z-scores greater than 2 or less than -2
outliers = ev_count_by_region[(ev_count_by_region['Z_Score'] > 2) | (ev_count_by_region['Z_Score'] < -2)]

# Print outliers to confirm
print(outliers)

"""**Remove the Outliers**"""

# Remove outliers from the original dataset
df_cleaned = ev_count_by_region[(ev_count_by_region['Z_Score'] <= 2) & (ev_count_by_region['Z_Score'] >= -2)]

# Alternatively, if working with the original data before aggregation:
# df_cleaned = df[~df['City'].isin(outliers['City'])]

"""**Verifying the Data After Removal**"""

# Check the cleaned dataset
print(df_cleaned.describe())
print(df_cleaned.head())

"""# Interpreting the Post-Removal Dataset:

After removing the outliers, dataset shows the following characteristics:

# EV_Count:
- Count: 813 cities/counties remain in the dataset.
- Mean: The average number of EVs per city/county is approximately 113.8.
- Standard Deviation (std): The standard deviation is 333.7, indicating a significant spread in EV counts, though this is expected given the nature of geographic data.
- Range: The min value is 1 EV, and the max value is 2,874 EVs.

# Z_Score:
- Mean: The mean Z-score is slightly negative (-0.093), which is typical when some high positive outliers have been removed.

- Range: Z-scores now range from approximately -0.175 to 1.93, which suggests that extreme outliers have been successfully removed, and only moderate variations remain.

**Visualization After Removal**
"""

import matplotlib.pyplot as plt
import seaborn as sns

# Boxplot to visualize the EV counts without outliers
plt.figure(figsize=(10, 6))
sns.boxplot(x=df_cleaned['EV_Count'])
plt.title('EV Count Distribution without Outliers')
plt.show()

"""**Visualize the Cleaned Data**"""

import matplotlib.pyplot as plt
import seaborn as sns

# Histogram of EV counts
plt.figure(figsize=(10, 6))
sns.histplot(df_cleaned['EV_Count'], bins=30, kde=True)
plt.title('Distribution of EV Counts (Outliers Removed)')
plt.xlabel('Number of EVs')
plt.ylabel('Frequency')
plt.show()

"""# Relevant Features for Outlier Analysis

The following numerical features are relevant for outlier analysis:

- Model Year
- Electric Range
- Base MSRP
- 2020 Census Tract

# Analyzing and Removing Outliers

- I will use the Z-score method to identify and remove outliers for each of these numerical features

**Calculate Z-Scores for Relevant Features**
"""

# Calculate Z-scores for each relevant feature
df['Model_Year_Z_Score'] = stats.zscore(df['Model Year'])
df['Electric_Range_Z_Score'] = stats.zscore(df['Electric Range'])
df['Base_MSRP_Z_Score'] = stats.zscore(df['Base MSRP'])
df['Census_Tract_Z_Score'] = stats.zscore(df['2020 Census Tract'])

"""**Identify Outliers**"""

# Identify and print outliers with Z-scores greater than 3 or less than -3

# Model Year Outliers
outliers_model_year = df[(df['Model_Year_Z_Score'] > 3) | (df['Model_Year_Z_Score'] < -3)]
print("Model Year Outliers:")
print(outliers_model_year[['Model Year', 'Model_Year_Z_Score']])
print("\n")

"""# Interpretation:

- The results indicate that 781 rows in your dataset were identified as outliers based on the Model Year feature. These rows have significantly low Z-scores, indicating that the model years of the vehicles in these rows are unusually older compared to the rest of the dataset.

**Z-Score Interpretation:**
- Z-Score of -3.296015: The majority of the outliers have a Z-score of approximately -3.3, which means that these model years are more than 3 standard deviations below the mean model year in your dataset. This is quite significant and suggests these years are much older than the average model year.
Z-Score of -3.629913: A small subset of the outliers has an even lower Z-score of around -3.63, indicating an even greater deviation from the mean.

**Specific Model Years:**
- The outliers are predominantly from the years 2010 and 2011. These years are considered outliers because the bulk of your dataset likely consists of vehicles from more recent years, making 2010 and 2011 stand out as significantly older.
"""

# Model Year Outliers Visualization
plt.figure(figsize=(10, 6))
sns.histplot(df['Model Year'], kde=True, color='blue', label='Original Data')
sns.histplot(outliers_model_year['Model Year'], kde=True, color='red', label='Outliers')
plt.title('Model Year - Before Outlier Removal')
plt.xlabel('Model Year')
plt.ylabel('Frequency')
plt.legend()
plt.show()

# Assuming df is your DataFrame
total_rows = df.shape[0]

# Print the total number of rows
print(f"The dataset contains {total_rows} rows.")

# Electric Range Outliers
outliers_electric_range = df[(df['Electric_Range_Z_Score'] > 3) | (df['Electric_Range_Z_Score'] < -3)]
print("Electric Range Outliers:")
print(outliers_electric_range[['Electric Range', 'Electric_Range_Z_Score']])
print("\n")

"""# Interpretation:

- The results indicate that 2,142 rows in your dataset were identified as outliers based on the Electric Range feature. These rows all have a significantly high Z-score, specifically around 3.03, indicating that the electric range of the vehicles in these rows is unusually high compared to the rest of the dataset.

**Z-Score Interpretation:**

- Z-Score of 3.026558: A Z-score of approximately 3.03 means that these electric ranges are more than 3 standard deviations above the mean electric range in your dataset. This indicates that these vehicles have significantly higher ranges than the typical vehicles in your dataset.

**Specific Electric Range:**

- The outliers are all associated with an electric range of 322 miles. This suggests that the vehicles identified as outliers are likely from a specific model or a few models that offer a much higher electric range than the average in your dataset.
"""

# Electric Range Outliers Visualization
plt.figure(figsize=(10, 6))
sns.histplot(df['Electric Range'], kde=True, color='blue', label='Original Data')
sns.histplot(outliers_electric_range['Electric Range'], kde=True, color='red', label='Outliers')
plt.title('Electric Range - Before Outlier Removal')
plt.xlabel('Electric Range')
plt.ylabel('Frequency')
plt.legend()
plt.show()

# Base MSRP Outliers
outliers_base_msrp = df[(df['Base_MSRP_Z_Score'] > 3) | (df['Base_MSRP_Z_Score'] < -3)]
print("Base MSRP Outliers:")
print(outliers_base_msrp[['Base MSRP', 'Base_MSRP_Z_Score']])
print("\n")

"""**Interpretation:**

- The results indicate that 3,319 rows in your dataset were identified as outliers based on the Base MSRP feature. These rows have significantly high Z-scores, with values around 7.06 and 8.50, indicating that the base MSRP (Manufacturer's Suggested Retail Price) of the vehicles in these rows is unusually high compared to the rest of the dataset.

**Z-Score Interpretation:**

- Z-Scores of 7.062127 and 8.496860: These Z-scores suggest that the base MSRP values in these rows are far above the mean MSRP in your dataset—more than 7 and 8 standard deviations, respectively, above the average. Such high Z-scores are extremely unusual, highlighting that these prices are significant outliers.

**Specific Base MSRP Values:**

- The outliers are associated with base MSRP values of $52,900 and $44,100. These values are consistently identified as outliers across many entries in the dataset.
"""

# Base MSRP Outliers Visualization
plt.figure(figsize=(10, 6))
sns.histplot(df['Base MSRP'], kde=True, color='blue', label='Original Data')
sns.histplot(outliers_base_msrp['Base MSRP'], kde=True, color='red', label='Outliers')
plt.title('Base MSRP - Before Outlier Removal')
plt.xlabel('Base MSRP')
plt.ylabel('Frequency')
plt.legend()
plt.show()

# 2020 Census Tract Outliers
outliers_census_tract = df[(df['Census_Tract_Z_Score'] > 3) | (df['Census_Tract_Z_Score'] < -3)]
print("2020 Census Tract Outliers:")
print(outliers_census_tract[['2020 Census Tract', 'Census_Tract_Z_Score']])
print("\n")

"""# Interpretation:

The results indicate that 360 rows in your dataset were identified as outliers based on the 2020 Census Tract feature. These rows have extremely low Z-scores, indicating that the 2020 Census Tract values in these rows are highly unusual compared to the rest of the dataset.

**Z-Score Interpretation:**

Extremely Low Z-Scores: The Z-scores range from approximately -8.67 to -30.49, which are exceptionally low. This means that the census tract numbers in these rows are far below the mean value in the dataset, deviating by many standard deviations from the average.

**Specific Census Tract Values:**

The outliers include census tract values like 8.035015e+09 and 4.013061e+09, among others. These values are flagged as outliers because they are significantly different from the rest of the dataset.
"""

# 2020 Census Tract Outliers Visualization
plt.figure(figsize=(10, 6))
sns.histplot(df['2020 Census Tract'], kde=True, color='blue', label='Original Data')
sns.histplot(outliers_census_tract['2020 Census Tract'], kde=True, color='red', label='Outliers')
plt.title('2020 Census Tract - Before Outlier Removal')
plt.xlabel('2020 Census Tract')
plt.ylabel('Frequency')
plt.legend()
plt.show()

"""# Remove Outliers"""

# Remove outliers from the dataset
df_cleaned = df[
    (df['Model_Year_Z_Score'] <= 3) & (df['Model_Year_Z_Score'] >= -3) &
    (df['Electric_Range_Z_Score'] <= 3) & (df['Electric_Range_Z_Score'] >= -3) &
    (df['Base_MSRP_Z_Score'] <= 3) & (df['Base_MSRP_Z_Score'] >= -3) &
    (df['Census_Tract_Z_Score'] <= 3) & (df['Census_Tract_Z_Score'] >= -3)
]

"""# Model Year - After Outlier Removal"""

plt.figure(figsize=(10, 6))
sns.histplot(df_cleaned['Model Year'], kde=True, color='green', label='Cleaned Data')
plt.title('Model Year - After Outlier Removal')
plt.xlabel('Model Year')
plt.ylabel('Frequency')
plt.legend()
plt.show()

"""# Electric Range - After Outlier Removal"""

plt.figure(figsize=(10, 6))
sns.histplot(df_cleaned['Electric Range'], kde=True, color='green', label='Cleaned Data')
plt.title('Electric Range - After Outlier Removal')
plt.xlabel('Electric Range')
plt.ylabel('Frequency')
plt.legend()
plt.show()

"""# Base MSRP - After Outlier Removal"""

plt.figure(figsize=(10, 6))
sns.histplot(df_cleaned['Base MSRP'], kde=True, color='green', label='Cleaned Data')
plt.title('Base MSRP - After Outlier Removal')
plt.xlabel('Base MSRP')
plt.ylabel('Frequency')
plt.legend()
plt.show()

"""# 2020 Census Tract - After Outlier Removal"""

plt.figure(figsize=(10, 6))
sns.histplot(df_cleaned['2020 Census Tract'], kde=True, color='green', label='Cleaned Data')
plt.title('2020 Census Tract - After Outlier Removal')
plt.xlabel('2020 Census Tract')
plt.ylabel('Frequency')
plt.legend()
plt.show()

"""# Display Summary of Outliers Identified & Remaining count after cleaning"""

# Displaying the number of outliers identified in each feature
outliers_summary = {
    "Feature": ["Model Year", "Electric Range", "Base MSRP", "2020 Census Tract"],
    "Outliers Identified": [
        outliers_model_year.shape[0],
        outliers_electric_range.shape[0],
        outliers_base_msrp.shape[0],
        outliers_census_tract.shape[0]
    ],
    "Original Count": [
        df.shape[0],
        df.shape[0],
        df.shape[0],
        df.shape[0]
    ],
    "Remaining Count After Cleaning": [
        df_cleaned.shape[0],
        df_cleaned.shape[0],
        df_cleaned.shape[0],
        df_cleaned.shape[0]
    ]
}

outliers_summary_df = pd.DataFrame(outliers_summary)
print(outliers_summary_df)

df.head()

# Check the total number of rows in the cleaned DataFrame
total_cleaned_rows = df_cleaned.shape[0]

# Print the total number of rows in the cleaned DataFrame
print(f"The cleaned dataset contains {total_cleaned_rows} rows.")

# Display the column names in the DataFrame
print(df.columns)

# Save the Cleaned and Standardized Dataset to Google Drive
cleaned_data_path = '/content/gdrive/My Drive/Colab Notebooks/Electiric vehical/standardized_cleaned_data.csv'
df.to_csv(cleaned_data_path, index=False)

# Confirm the dataset is saved and display the first few rows of the cleaned data
print(f"Cleaned and standardized dataset saved to {cleaned_data_path}")
print(df.head())

# Access your dataset
data_path = '/content/gdrive/My Drive/Colab Notebooks/Electiric vehical/standardized_cleaned_data.csv'

df = pd.read_csv(data_path)
# Display the first few rows of the DataFrame
df.head()

from scipy import stats

# List of numerical columns to check for outliers
numerical_columns = ['Postal Code', 'Model Year', 'Electric Range', 'Base MSRP', 'DOL Vehicle ID', '2020 Census Tract']

# Recalculate Z-scores for these columns
z_scores = df[numerical_columns].apply(stats.zscore)

# Check for any remaining outliers
outliers_remaining = (z_scores.abs() > 3).sum()

# Display the number of outliers remaining for each feature
print("Remaining outliers in each feature:")
print(outliers_remaining)

from scipy import stats

# List of numerical columns to check for outliers
numerical_columns = ['Postal Code', 'Model Year', 'Electric Range', 'Base MSRP', 'DOL Vehicle ID', '2020 Census Tract']

# Recalculate Z-scores for these columns
z_scores = df[numerical_columns].apply(stats.zscore)

# Remove rows with any outliers in these features
df_cleaned = df[(z_scores.abs() <= 3).all(axis=1)]

# Verify if the outliers have been removed
remaining_outliers = (df_cleaned[numerical_columns].apply(stats.zscore).abs() > 3).sum()

# Display the number of outliers remaining for each feature
print("Remaining outliers in each feature (after final cleaning):")
print(remaining_outliers)

# Display the number of rows remaining
print(f"The dataset contains {df_cleaned.shape[0]} rows after removing outliers.")

# Confirm that the DataFrame is not empty and has the expected structure
print(df_cleaned.info())
print(df_cleaned.head())

from scipy import stats

# List of numerical columns to check for outliers
numerical_columns = ['Postal Code', 'Model Year', 'Electric Range', 'Base MSRP', 'DOL Vehicle ID', '2020 Census Tract']

# Recalculate Z-scores for these columns
z_scores = df[numerical_columns].apply(stats.zscore)

# Remove rows with any outliers in these features
df_cleaned = df[(z_scores.abs() <= 3).all(axis=1)]

# Verify if the outliers have been removed
remaining_outliers = (df_cleaned[numerical_columns].apply(stats.zscore).abs() > 3).sum()

# Display the number of outliers remaining for each feature
print("Remaining outliers in each feature (after final cleaning):")
print(remaining_outliers)

# Display the number of rows remaining
print(f"The dataset contains {df_cleaned.shape[0]} rows after removing outliers.")

# Define the path to save the cleaned dataset
cleaned_data_final_path = '/content/gdrive/My Drive/Colab Notebooks/Electiric vehical/cleaned_data_no_outliers.csv'

# Save the cleaned DataFrame to a CSV file
df_cleaned.to_csv(cleaned_data_final_path, index=False)

# Print confirmation
print(f"Final cleaned dataset saved to {cleaned_data_final_path}")

# List files in the target directory to confirm the file is saved
import os

# Path to the directory where the file should be saved
directory_path = '/content/gdrive/My Drive/Colab Notebooks/Electiric vehical/'

# List the files in the directory
files_in_directory = os.listdir(directory_path)

# Check if the file is present
if 'cleaned_data_no_outliers.csv' in files_in_directory:
    print("File successfully saved.")
else:
    print("File not found. Something went wrong with the saving process.")

# Load the saved cleaned dataset
df_loaded = pd.read_csv(cleaned_data_final_path)

# Check the number of rows in the reloaded dataset
print(f"The reloaded dataset contains {df_loaded.shape[0]} rows.")

# Display the first few rows to verify the content
print(df_loaded.head())

"""**Remove the Outliers**"""

from scipy import stats

# Load the saved cleaned dataset
cleaned_data_final_path = '/content/gdrive/My Drive/Colab Notebooks/Electiric vehical/cleaned_data_no_outliers.csv'
df_loaded = pd.read_csv(cleaned_data_final_path)

# Recalculate Z-scores for 'Model Year' and 'Electric Range'
df_loaded['Model_Year_Z_Score'] = stats.zscore(df_loaded['Model Year'])
df_loaded['Electric_Range_Z_Score'] = stats.zscore(df_loaded['Electric Range'])

# Remove outliers from 'Model Year' and 'Electric Range'
df_cleaned_final = df_loaded[
    (df_loaded['Model_Year_Z_Score'].abs() <= 3) &
    (df_loaded['Electric_Range_Z_Score'].abs() <= 3)
]

# Drop the Z-score columns as they are no longer needed
df_cleaned_final = df_cleaned_final.drop(columns=['Model_Year_Z_Score', 'Electric_Range_Z_Score'])

# Check the number of rows remaining after removing these outliers
print(f"Number of rows after removing outliers from 'Model Year' and 'Electric Range': {df_cleaned_final.shape[0]}")

# Check the number of rows in the final cleaned dataset
final_row_count = df_cleaned_final.shape[0]

# Display the number of rows
print(f"The final cleaned dataset contains {final_row_count} rows.")

# List of numerical columns to check for outliers
numerical_columns = ['Postal Code', 'Model Year', 'Electric Range', 'Base MSRP', 'DOL Vehicle ID', '2020 Census Tract']

# Recalculate Z-scores for these columns
df_cleaned_final_zscores = df_cleaned_final[numerical_columns].apply(stats.zscore)

# Check for any remaining outliers in all features
remaining_outliers_all_features = (df_cleaned_final_zscores.abs() > 3).sum()

# Display the number of outliers remaining for each feature
print("Remaining outliers in each feature after final cleaning:")
print(remaining_outliers_all_features)

# List of numerical columns to visualize
numerical_columns = ['Postal Code', 'Model Year', 'Electric Range', 'Base MSRP', 'DOL Vehicle ID', '2020 Census Tract']

# Create histograms and box plots for each numerical feature after cleaning
for col in numerical_columns:
    plt.figure(figsize=(14, 6))

    # Histogram
    plt.subplot(1, 2, 1)
    sns.histplot(df_cleaned_final[col], kde=True)
    plt.title(f'{col} - Histogram After Outlier Removal')

    # Box plot
    plt.subplot(1, 2, 2)
    sns.boxplot(df_cleaned_final[col])
    plt.title(f'{col} - Box Plot After Outlier Removal')

    plt.show()

# Identify any Z-score columns in the DataFrame
z_score_columns = [col for col in df_cleaned_final.columns if 'Z_Score' in col]

# Drop the Z-score columns if they exist
df_cleaned_final = df_cleaned_final.drop(columns=z_score_columns, errors='ignore')

# Verify that the Z-score columns have been removed
print("Remaining columns after dropping Z-score columns:")
print(df_cleaned_final.columns)

# Save the cleaned dataset without the outliers
final_data_path = '/content/gdrive/My Drive/Colab Notebooks/Electiric vehical/final_cleaned_data.csv'
df_cleaned_final.to_csv(final_data_path, index=False)

print(f"Final cleaned dataset saved to {final_data_path}")

# Load the final cleaned dataset
final_data_path = '/content/gdrive/My Drive/Colab Notebooks/Electiric vehical/final_cleaned_data.csv'
df_final = pd.read_csv(final_data_path)

# Check the total number of rows and columns in the dataset
total_rows = df_final.shape[0]
total_columns = df_final.shape[1]

# Display the number of rows and columns
print(f"Total rows: {total_rows}, Total columns: {total_columns}")

